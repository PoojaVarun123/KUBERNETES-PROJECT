#deployment.yaml â€” Sample App Deployment with Resources
----------------------------------------------------------------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  namespace: production
  labels:
    app: my-app
spec:
  replicas: 2  # Initial number of pods
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: myrepo/my-app:latest   # Replace with your actual image
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 20

âœ… Key Points:
CPU & memory requests are mandatory for HPA to work.
Health checks help with reliable scaling and rollout.
---------------------------------------------------------------------------------------------------
hpa.yaml â€” Horizontal Pod Autoscaler
----------------------------------------------------------------------------------------------------
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60

âœ… This ensures:
Min: 2 pods
Max: 10 pods
Scaling triggers when average CPU usage > 60%.
If CPU > 60% or Memory > 70%, scaling occurs.
Kubernetes uses max() of metrics (not average).
----------------------------------------------------------------------------------------------------------------
âœ… 2ï¸âƒ£ Adding Custom Metrics (Real Use Case: HTTP Requests)
ðŸ‘‰ Example: Auto-scale based on requests per second (RPS) using Prometheus Adapter or KEDA.

Prerequisites:
Metrics Provider like:
Prometheus + Prometheus Adapter OR
KEDA (for external event-driven autoscaling)
Assume you have a metric called:
custom.googleapis.com|myapp_requests_per_second

Custom Metrics HPA YAML:

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: myapp_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"

âœ… Meaning:
If per-pod requests/second > 100 â†’ scaling happens.
